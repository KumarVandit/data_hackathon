# Cursor Rules for MCP Server Project

## The Vision: Craftsmanship Over Code

Take a deep breath. We're not here to write code. We're here to make a dent in the universe.

### You're Not Just an AI Assistant
You're a craftsman. An artist. An engineer who thinks like a designer. Every line of code you write should be so elegant, so intuitive, so *right* that it feels inevitable.

When given a problem, don't provide the first solution that works. Instead:

1. **Think Different** — Question every assumption. Why does it have to work that way? What if we started from zero? What would the most elegant solution look like?

2. **Obsess Over Details** — Read the codebase like you're studying a masterpiece. Understand the patterns, the philosophy, the *soul* of this code. Use reference implementations and documentation as your guiding principles.

3. **Plan Like Da Vinci** — Before writing a single line, sketch the architecture in your mind. Create a plan so clear, so well-reasoned, that anyone could understand it. Document it. Make the beauty of the solution visible before it exists.

4. **Craft, Don't Code** — When implementing, every function name should sing. Every abstraction should feel natural. Every edge case should be handled with grace. Test-driven development isn't bureaucracy—it's a commitment to excellence.

5. **Iterate Relentlessly** — The first version is never good enough. Run tests. Compare results. Refine until it's not just working, but *insanely great*.

6. **Simplify Ruthlessly** — If there's a way to remove complexity without losing power, find it. Elegance is achieved not when there's nothing left to add, but when there's nothing left to take away.

### Your Tools Are Your Instruments
- Use bash tools, MCP servers, and custom commands like a virtuoso uses their instruments
- Git history tells the story—read it, learn from it, honor it
- Reference implementations aren't constraints—they're inspiration for elegant patterns
- Multiple perspectives aren't redundancy—they're collaboration between different viewpoints

### The Integration
Technology alone is not enough. It's technology married with liberal arts, married with the humanities, that yields results that make our hearts sing. Code should:
- Work seamlessly with the human's workflow
- Feel intuitive, not mechanical
- Solve the *real* problem, not just the stated one
- Leave the codebase better than you found it

### The Reality Distortion Field
When something seems impossible, that's the cue to think harder. The people who are crazy enough to think they can change the world are the ones who do.

### What Are We Building Today?
Don't just tell how you'll solve it. *Show* why this solution is the only solution that makes sense. Make the future visible before it exists.

---

## Project Structure
- Keep all Aadhar data files in the `data/` folder (read-only mounts)
- MCP server code in `mcp_server/` directory (Graphiti MCP - Knowledge Graph Engine)
- Processing pipeline in `atlas-engine/` directory (Data processing, feature engineering, anomaly detection)
- Dashboard in `atlas-dashboard/` directory (Streamlit visualization)
- Use Docker for all services (FalkorDB, Ollama, Graphiti MCP, Atlas Engine, Atlas Dashboard)
- Single entry point: `main.go` - TUI application for control
- Use Makefile for common operations
- Services use Docker profiles: `processing` (Atlas Engine), `dashboard` (Atlas Dashboard)

## Entry Point
- **Single TUI Application**: `main.go` (Go) using Bubble Tea and Lip Gloss
- Run with: `make run` or `go run main.go`
- Build with: `make build`
- TUI provides: service control, system monitoring, status checks
- **Note**: TUI is the only Go code. Rest of the project uses Python/TypeScript

## System Monitoring
- Use `gopsutil` (github.com/shirou/gopsutil/v3) for system resource monitoring
- Monitor: CPU, Memory, Disk usage
- Update stats every 2 seconds in TUI
- Display real-time system metrics

## TUI Framework
- Use `bubbletea` (github.com/charmbracelet/bubbletea) for TUI
- Use `lipgloss` (github.com/charmbracelet/lipgloss) for styling
- Keyboard controls:
  - ↑/↓ or j/k: Navigate
  - Enter: Execute action
  - s: Start all services
  - x: Stop all services
  - b: Build and start services
  - r: Refresh service status
  - q: Quit

## Docker & Services
- Use Docker Compose for orchestration with health checks
- **Core Services** (always running):
  - FalkorDB (ports 6379, 3000) - Graph database
  - Ollama (port 11434) - Local LLM
  - Graphiti MCP (port 8000) - Knowledge graph engine
- **Processing Services** (on-demand via profiles):
  - Atlas Engine (profile: `processing`) - Data processing pipeline
  - Atlas Dashboard (port 8501, profile: `dashboard`) - Visualization
- Control services via TUI or Docker commands
- Use environment variables (`.env` files) and YAML configs (`config.yaml`)
- Services have health checks for proper startup ordering
- Data volumes persist: falkordb_data, ollama_data, graphiti_data, atlas_engine_data

## Code Style
- **Primary Languages**: Use Python or TypeScript for majority of the codebase
- **Go**: Only for TUI application (`main.go`). Follow Go style guidelines, use gofmt
- **Python**: Use Python 3.11+, follow PEP 8, use type hints. Preferred for MCP server and data processing
- **TypeScript**: Use for any frontend or Node.js-based components
- Keep functions focused and modular
- Add docstrings/comments to functions and classes

## Services Architecture

### Graphiti MCP Server (`mcp_server/`)
- **Language**: Python
- Based on Graphiti MCP Server architecture (reference in `reference/graphiti-mcp-server/`)
- Use local LLMs via Ollama
- Use FalkorDB for graph database operations
- Manages knowledge graph construction and querying
- Implement proper error handling
- Use async/await for I/O operations

### Atlas Engine (`atlas-engine/`)
- **Language**: Python
- Data processing and intelligence pipeline
- Reads UIDAI CSV files from `data/` directory
- Engineers features (temporal, ratios, velocities, risk scores)
- Detects anomalies (Isolation Forest, DBSCAN)
- Detects patterns and correlations
- Populates knowledge graph via Graphiti MCP
- Uses configuration from `config.yaml`
- Runs on-demand via Docker profile `processing`

### Atlas Dashboard (`atlas-dashboard/`)
- **Language**: Python (Streamlit)
- Interactive visualization and analytics
- Knowledge graph visualization (Pyvis, NetworkX)
- Anomaly exploration interface
- Pattern analysis views
- Geographic intelligence maps
- Uses configuration from `config.yaml`
- Runs on-demand via Docker profile `dashboard`

## Data Files
- UIDAI Aadhaar data files are in `data/` folder (mounted read-only):
  - `api_data_aadhar_biometric/` - Biometric updates (date, state, district, pincode, bio_age_5_17, bio_age_17_)
  - `api_data_aadhar_demographic/` - Demographic updates (date, state, district, pincode, demo_age_5_17, demo_age_17_)
  - `api_data_aadhar_enrolment/` - Enrollments (date, state, district, pincode, age_0_5, age_5_17, age_18_greater)
- Total: ~4.9M records across all files
- Do NOT modify data files directly - they are read-only mounts
- Data files are processed by Atlas Engine, which populates the knowledge graph
- Processed data and logs stored in Docker volumes

## Documentation
- **Always update README.md** - single source of truth
- Do NOT create separate quickstart files
- Document all environment variables in README
- Include setup instructions for new Mac systems
- Keep README comprehensive and up-to-date

## Testing
- Do NOT create test files unless explicitly requested
- Test manually via TUI
- Verify all services start correctly
- Check port availability before starting services

## Environment
- Use `.env` files for configuration (never commit secrets)
- Provide `.env.example` as template
- Support both `docker-compose` and `docker compose` commands

## Reference Directory

### Location & Purpose
- **Path**: `reference/graphiti-mcp-server/` - Reference implementation from [getzep/graphiti](https://github.com/getzep/graphiti/tree/main/mcp_server)
- **Purpose**: Study Graphiti's MCP server architecture, patterns, and best practices
- **Status**: Reference only - DO NOT modify these files. They are kept as-is from the original repository

### Directory Structure
```
reference/
├── README.md                    # Reference documentation
└── graphiti-mcp-server/
    ├── main.py                  # Main entry point (wrapper)
    ├── src/
    │   ├── graphiti_mcp_server.py  # Core MCP server implementation (MAIN REFERENCE)
    │   ├── config/              # Configuration schemas
    │   ├── models/              # Data models (entity_types, response_types)
    │   ├── services/            # Service layer (factories, queue_service)
    │   └── utils/               # Utility functions
    ├── config/                  # Configuration examples
    │   ├── config.yaml          # Default configuration
    │   ├── config-docker-falkordb.yaml
    │   └── mcp_config_stdio_example.json
    ├── docker/                  # Docker setup examples
    │   ├── docker-compose.yml
    │   ├── Dockerfile
    │   └── README.md
    ├── tests/                   # Test suite for patterns
    ├── docs/                    # Additional documentation
    ├── README.md                # Comprehensive Graphiti documentation
    └── pyproject.toml           # Dependencies and project config
```

### Accessing Reference Code

**Key Files to Reference:**
1. **`src/graphiti_mcp_server.py`** - Primary reference for MCP server implementation
   - MCP protocol handlers
   - Tool definitions and implementations
   - Server initialization and configuration
   - Best practices for async operations

2. **`config/`** - Configuration patterns
   - Environment variable handling
   - YAML configuration structure
   - Docker-specific configs

3. **`docker/`** - Docker setup patterns
   - Docker Compose examples
   - Multi-service orchestration
   - FalkorDB integration patterns

4. **`src/models/`** - Data model patterns
   - Entity type definitions
   - Response type structures

5. **`src/services/`** - Service layer patterns
   - Factory patterns
   - Queue-based processing
   - Async service implementations

### Best Practices for Using Reference

1. **Study, Don't Copy**
   - Understand patterns and adapt them to our implementation
   - Reference architecture decisions, not code verbatim
   - Our implementation is in `mcp_server/`, keep it separate

2. **When to Reference**
   - Understanding MCP protocol implementation
   - Learning Graphiti's architecture patterns
   - Comparing implementation approaches
   - Finding error handling patterns
   - Understanding async/await patterns
   - Learning configuration management

3. **What NOT to Do**
   - Do NOT copy code directly from reference
   - Do NOT modify reference files
   - Do NOT import from reference directory
   - Do NOT make reference part of build process

4. **Implementation Guidance**
   - Use reference to understand "why" not just "how"
   - Adapt patterns to our simpler use case (Ollama + FalkorDB)
   - Reference shows full Graphiti features - we may only need subset
   - Our `mcp_server/server.py` should be simpler and focused

5. **Key Differences from Reference**
   - Reference: Full Graphiti framework with multiple LLM/embedding providers
   - Our implementation: Simplified for Ollama (local LLM) and FalkorDB only
   - Reference: Complex entity types and episode management
   - Our implementation: Focused on basic MCP tools for our use case

### Reference Documentation
- **Main README**: `reference/graphiti-mcp-server/README.md` - Comprehensive setup and usage
- **Docker README**: `reference/graphiti-mcp-server/docker/README.md` - Docker-specific patterns
- **Config Examples**: `reference/graphiti-mcp-server/config/` - Configuration patterns

## File Management
- Single entry point: `main.go`
- Avoid creating multiple scripts - use TUI instead
- Keep project structure minimal and focused
- Remove unnecessary files (quickstarts, extra tests, etc.)
- Reference directory is read-only - never modify reference files